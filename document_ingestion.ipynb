{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "23bf1adc",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Target path d:\\Utkarsh\\UTKARSH\\GenAI\\Ready Tensor Agentic AI\\LangGraph_documentation_RAG\\langgraph_documentation_RAG\\docs\\source_docs already exists. Removing for fresh clone.\n",
            "Copying from local cache langgraph_repo/docs/docs to d:\\Utkarsh\\UTKARSH\\GenAI\\Ready Tensor Agentic AI\\LangGraph_documentation_RAG\\langgraph_documentation_RAG\\docs\\source_docs...\n",
            "\n",
            " Saved 5365 chunks to docs\\chunked_docs\\chunked_docs.json\n",
            "Generating embeddings for 5365 chunks...\n",
            "Uploading embeddings to Qdrant...\n",
            "âœ… Uploaded 5365 embeddings to collection 'langgraph_docs'\n"
          ]
        }
      ],
      "source": [
        "from vector_database.src.documentation_loader import load_config, clone_repo, cleanup_old_outputs, load_documents\n",
        "from vector_database.src.text_splitter import chunk_documents, save_chunks_to_disk\n",
        "from vector_database.src.vector_store import store_embeddings\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "from pathlib import Path\n",
        "\n",
        "# 1. Load environment\n",
        "load_dotenv()\n",
        "\n",
        "# 2. Load config\n",
        "config_path = Path(\"config.yaml\")\n",
        "config = load_config(config_path)\n",
        "\n",
        "# 3. Cleanup old data\n",
        "cleanup_old_outputs()\n",
        "clone_repo(config)\n",
        "\n",
        "# 4. Load documents\n",
        "docs_path = config['data_source']['github']['target_path']\n",
        "all_docs = load_documents(docs_path)\n",
        "\n",
        "# 5. Chunk and save\n",
        "chunks = chunk_documents(all_docs, config)\n",
        "save_chunks_to_disk(chunks)\n",
        "\n",
        "# 6. Store embeddings to Qdrant\n",
        "store_embeddings(chunks, config)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "langgraph-documentation-rag-0Hg_gMbX-py3.13",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
