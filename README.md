
# ğŸ¤– LangGraph Documentation RAG Assistant

A **Retrieval-Augmented Generation (RAG)** agent designed to answer technical questions from the **LangGraph documentation** using its own text corpus. This project integrates **LangGraph** workflows, **LangChain**, **Qdrant** vector database, and **OpenAI** embeddings + GPT-4 to build a fully functional domain-specific assistant.

---


## ğŸ§  Architecture Overview


![flows](https://github.com/user-attachments/assets/5b901790-8753-47fb-be2c-f06aa0590f49)


---

## âš™ï¸ Tech Stack

| Component        | Tool / Service              | Purpose                           |
|------------------|-----------------------------|-----------------------------------|
| **LLM**          | OpenAI GPT-4                | Response generation               |
| **Embeddings**   | `text-embedding-3-large`    | Document vectorization            |
| **Agent Logic**  | LangGraph                   | Agent and tool-based workflow     |
| **Vector DB**    | Qdrant                      | Document chunk retrieval          |
| **Prompting**    | LangChain                   | Modular prompt orchestration      |
| **Environment**  | Poetry                      | Dependency & virtual env setup    |

---

## ğŸš€ Features

- ğŸ“š Uses official LangGraph documentation as source
- ğŸ” Semantic search via Qdrant
- ğŸ§  Modular prompts with ReAct-style reasoning
- ğŸ”„ LangGraph-driven state-based retrieval and generation
- ğŸ’¬ Supports multi-turn memory (within LangGraph state)

---

## ğŸ“‚ Project Structure

```
.
â”œâ”€â”€ main.py                       # Runs document ingestion pipeline
â”œâ”€â”€ publication.md               # Technical write-up
â”œâ”€â”€ prompts/                     # YAML-based prompt templates
â”œâ”€â”€ rag_pipeline/                # Core agent orchestration
â”œâ”€â”€ test_notebooks/             # Prompt testing and demo notebooks
â”œâ”€â”€ vector_database/            # Qdrant vector store integration
â”œâ”€â”€ example.env                  # Sample environment config
â”œâ”€â”€ config.yaml                  # Global config for chunking, DB, etc.
â”œâ”€â”€ README.md                    # Youâ€™re reading it :)
â””â”€â”€ docs/
    â””â”€â”€ architecture.png         # ğŸ–¼ï¸ Place your diagram here
```

---

## ğŸ› ï¸ Setup Instructions

### 1. Clone the Repository

```bash
git clone https://github.com/your-username/langgraph_documentation_RAG
cd langgraph_documentation_RAG
```

### 2. Install Dependencies with Poetry

```bash
curl -sSL https://install.python-poetry.org | python3 -
poetry install
poetry shell
```

### 3. Set Up Environment Variables

Create a `.env` file using the sample provided:

```bash
cp example.env .env
```

Then update your `.env` with your OpenAI API key:

```
OPENAI_API_KEY=your-key-here
```

---

## ğŸ§ª Run the Ingestion Pipeline

```bash
poetry run python main.py
```

This will:
- Clone LangGraph documentation repo
- Load and chunk files
- Store vectorized content into Qdrant

---

## ğŸ““ Example Notebooks

Test and interact with the assistant in the following Jupyter notebooks:

- `test_notebooks/rag_example.ipynb`
- `test_notebooks/prompt_template_example.ipynb`

---

## ğŸ’¡ Example Queries

```text
â€œWhat is the difference between a LangGraph workflow and an agent?â€

â€œHow can I use checkpoints or memory between steps in LangGraph?â€

â€œExplain multi-agent routing with LangGraph.â€
```

---

## ğŸ”– License

This project is open source and available under the **MIT License**.

---

## ğŸ‘¥ Contributors

- **Pranav Tiwari** â€“ Research + Publication  
- **Utkarsh** â€“ Vector DB Engineering  
- **Manuel** â€“ LangGraph Agent Implementation

---

## ğŸ“« Contact Open to collaboration and contributions: 
ğŸ“§ Email: [mailto:tu_email@ejemplo.com, tiwari.pranav1999@gmail.com, utkarsh251096@gmail.com] 
ğŸŒ GitHub: tu_usuario
